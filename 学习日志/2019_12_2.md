#### 1. 学习并翻译：PyTorch Tutorial: [*Saving and Loading Models*](https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict)  
##### Author: Matthew Inkawhich
本文档提供了关于保存和加载PyTorch模型的各种用例的解决方案。您可以随意阅读整个文档，或者直接跳到所需用例所需代码。  
在保存和加载模型时，有三个核心功能需要熟悉：  
1. `torch.save`: 将序列化对象保存到磁盘。该函数使用Python的pickle实用程序进行序列化。使用这个函数可以保存各种对象的模型、张量和字典。  
2. `torch.load`: 使用pickle的反pickle功能将pickle的对象文件反序列化到内存中。这个功能也方便了设备加载数据(参见设备间的保存和加载模型)。  
3. `torch.nn.Module.load_state_dict`: 使用反序列化的state_dict加载模型的参数字典。有关state_dict的更多信息，请参见什么是state_dict?  
##### Contents:
* <a href="#1">state_dict是什么?</a>  
* 保存和加载推理模型  
* 保存和加载一个通用检查点  
* 将多个模型保存在一个文件中  
* 使用来自不同模型的参数对模型进行预热  
* 跨设备的保存和加载模型  
<a name="1">##### What is a state_dict?</a>
在PyTorch中，`torch.nn.Module`模型的可学习参数（i.e. 权重和偏差）包含在模型的参数中（可通过model.parameters（）访问）。state_dict只是一个Python字典对象，它将每个图层映射成它的参数张量。请注意，只有具有可学习参数的图层(convolutional layers, linear layers, etc.)和注册缓冲区 (batchnorm’s running_mean)在模型的state_dict中有条目。优化器对象（torch.optim）也具有state_dict，这个state_dict包含有关优化器状态以及所用超参数的信息。  
由于state_dict对象是Python的dictionary类型，因此可以轻松地保存，更新，更改和还原它们，从而为PyTorch的models和optimizers增加了大量的模块化。  
###### Example:  
让我们看一下训练分类器教程中使用的简单模型中的state_dict。  
```python
# Define model
class TheModelClass(nn.Module):
    def __init__(self):
        super(TheModelClass, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Initialize model
model = TheModelClass()

# Initialize optimizer
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Print model's state_dict
print("Model's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())

# Print optimizer's state_dict
print("Optimizer's state_dict:")
for var_name in optimizer.state_dict():
    print(var_name, "\t", optimizer.state_dict()[var_name])  
```  
###### outputs:  
```python
Model's state_dict:
conv1.weight     torch.Size([6, 3, 5, 5])
conv1.bias   torch.Size([6])
conv2.weight     torch.Size([16, 6, 5, 5])
conv2.bias   torch.Size([16])
fc1.weight   torch.Size([120, 400])
fc1.bias     torch.Size([120])
fc2.weight   torch.Size([84, 120])
fc2.bias     torch.Size([84])
fc3.weight   torch.Size([10, 84])
fc3.bias     torch.Size([10])

Optimizer's state_dict:
state    {}
param_groups     [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [4675713712, 4675713784, 4675714000, 4675714072, 4675714216, 4675714288, 4675714432, 4675714504, 4675714648, 4675714720]}]
```
